### 
# Hausa Data collected by Tim Schlippe and al.
# Prepared by Elodie Gauthier & Laurent Besacier
# GETALP LIG, Grenoble, France
###

### IMPORTANT FOREWORD

To be able to train/test this hausa ASR system, you need to buy the necessary corpora available on ELDA catalog
-Corpus GlobalPhone Hausa :  http://catalog.elra.info/product_info.php?products_id=1177 
8h44mn of transcribed speech

-Pronunciation dictionary GlobalPhone Hausa :  http://catalog.elra.info/product_info.php?products_id=1203 
42662 lexicon input

-Once acquired, the wav files must be copied in data/(train,dev,test)/wav directories following the protocol/organization mentionned in data/(train,dev,test)/utt2spk ; the prononciation dictionary must be copied in lang/lexicon.txt. You can have a preview of the pronunciation dictionary in the lang/ directory.

### OVERVIEW
The package contains hausa speech corpus with audio data in the directory data/. The data directory contains 3 subdirectories:
a. train/ - speech data and transription for training automatic speech recognition system (Kaldi ASR format [1])
b. dev/ - speech data and transcription for testing automatic speech recognition system (Kaldi ASR format) 
c. test/ - speech data and transription for evaluating automatic speech recognition system (Kaldi ASR format)

A text corpus and language model in the directory LM/, a sample of the lexicon in the directory lang/, some scripts you need to run before started anything in formatting_scripts/ and the Kaldi scripts in kaldi-scripts/ 
 
### PUBLICATION ON HAUSA SPEECH & LM DATA
More details on the corpus and how it was collected can be found on the following publication (please cite this bibtex if you use this data)

 @InProceedings { schlippe:hausa,
  author = {Tim Schlippe and Edy Guevara Komgang Djomgang and Ngoc Thang Vu and Sebastian Ochs and Tanja Schultz},
  title = {Hausa large vocabulary continuous speech recognition},
  booktitle = {{SLTU} - {W}orkshop on {S}poken {L}anguage {T}echnologies for {U}nder-{R}esourced {L}anguages},
  year = {2012},
  address = {Cape-Town, Afrique Du Sud},
  abstract = {no abstract},
  x-international-audience = {yes},
  pages = {11-14}
  url = {http://www.mica.edu.vn/sltu2012/files/proceedings/3.pdf},
}

### HAUSA SPEECH CORPUS
Directory: /data/train
Files: text (training transcription), wav.scp (file id and path), utt2spk (file id and audio id), spk2utt (audio id and file id), wav (empty but must contains .wav files), trsTrain.txt (training transcription and wav file id), cmvn.scp and feats.scp (auto-generated by script 01_init_datas.sh but necessary if you want to test immediatly the system by starting at the 02_lexicon.sh script. 
For more information about the format, please refer to Kaldi website http://kaldi.sourceforge.net/data_prep.html
Description: training data in Kaldi format about 7 hours. 
Note: The path of wav files in wav.scp have to be modified to point to the actual location, as paths in utt2spk, spk2utt.

Directory: /data/dev
Files: text (dev transcription), wav.scp (file id and path), utt2spk (file id and audio id), spk2utt (audio id and file id), wav (empty but must contains .wav files), trsDev.txt (dev transcription and wav file id), cmvn.scp and feats.scp, hausa_dev.ref (used to scoring the output system at the end with the script result-sclite-hausa.sh).
Description: training data in Kaldi format about 1 hour. 
Note: The path of wav files in wav.scp have to be modified to point to the actual location, as paths in utt2spk, spk2utt.

Directory: /data/test
Files: text (test transcription), wav.scp (file id and path), utt2spk (file id and audio id), spk2utt (audio id and file id), wav (empty but must contains .wav files), trsTest.txt (test transcription and wav file id), cmvn.scp and feats.scp.
Description: testing data in Kaldi format about 1 hour.
Note: The path of wav files in wav.scp have to be modified to point to the actual locatiion, as paths in utt2spk, spk2utt. 

Note : The audio corpus you have acquired is in a raw format .adc . For Kaldi scripts work, you need .wav format. To convert those files, you have to run the python script adc2wav.py which is in formatting_data/ directory. Once converted, the  audio files are classified by speaker's id with one directory for each (e.g.: "OO1", "002", "003", ...). In this speaker directory, you will find one .wav file corresponding to one utterance in the transcription file (i.e.: "text"). The format of the .wav file is "HA{speaker id}_{utterance id}.wav" (e.g.: "HA001_1.wav" "HA098_17.wav", etc.). You have to put adc2wav.py script in the same directory as adc/ but outside (e.g.: path of adc: audio_data/adc/*   ;   path of adc2wav.py script: audio_data/adc2wav.py) 


### HAUSA TEXT CORPUS
Directory: /LM
Files: HAU.3gram_Tolower.arpa, textTrain.trs, hausa.arpa, hausa.vocab

# /HAU.3gram_Tolower.arpa
Contains 41k words. Transcribed speech data from GlobalPhone corpus and converted into lower case. The original language model can be found on http://csl.ira.uka.de/GlobalPhone/

# /textTrain.trs
Transcriptions of the training data corpus for LM

# /hausa.arpa
A language model created using SRILM [2] using the text from textTrain.trs 

# /hausa.vocab
Words used in hausa.arpa language model 


### LEXICON/PRONUNCIATION DICTIONARY
Directory: lang/
Files: small_lexicon.txt (lexicon sample), nonsilence_phones.txt (speech phones), optional_silence.txt (silence phone)
Description: lexicon sample contains words and their respective pronunciation, non-speech sound and noise in Kaldi format. 
Note: The lexicon no including tone and vowel length information.


### SCRIPTS
In formatting_scripts/ you find scripts used to format the data acquired.
a. GPDictHAscript.py python script formats the lexicon.txt 
b. adc2wav.py python script formats the audio data. 

In kaldi-scripts/ you find the scripts used to train and test models
(path has to be changed to make it works in your own directory!)
From the existing data and lang directory you can directly run 02_lexicon.sh and 03_LM.sh in order to create all the files needed for next Kaldi scripts. Then, you can run 000_kaldi.sh. It starts the sequence : 04_train_mono.sh + 04a_train_triphone.sh + 04b_train_MLLT_LDA.sh + 04c_train_SAT_FMLLR.sh + 04d_train_MMI_FMMI.sh + 04e_train_sgmm.sh . 
Note: You have to run the script 00_init_paths.sh before run any script (as from 01_init_datas.sh)

At this end of each Kaldi scripts, you obtain some WER score, but no alignment reference/hypothesis or global score. For this, you can run the script results-sclite-hausa.sh. However, to use this script you have to install the program sclite [3] and to change all path in the script they are appropriate for your data.

 
### WER RESULTS OBTAINED SO FAR (you should obtain the same on this data if same protocol used)
# These results were obtained from the Kaldi's version of June 2014
Monophone (13 MFCC): 24.38% 
Triphone (13 MFCC): 16.75%
Triphone (13 MFCC + delta + delta2): 16.99%
Triphone (39 features) + LDA and MLLT: 16.46% 
Triphone (39 features) + LDA and MLLT + SAT and FMLLR: 13.25%
Triphone (39 features) + LDA and MLLT + SAT and FMLLR + MMI: 11.89%
Triphone (39 features) + LDA and MLLT + SGMM: 10.04%
Triphone (39 features) + LDA and MLLT + SGMM + MMI: 9.93%


### REFERENCES
[1] KALDI: http://kaldi.sourceforge.net/tutorial_running.html
[2] SRILM: http://www.speech.sri.com/projects/srilm/
[3] Sclite: http://www1.icsi.berkeley.edu/Speech/docs/sctk-1.2/sclite.htm
